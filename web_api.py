#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¤šç”¨æˆ·ç‰ˆFastAPI - å›ºå®šä½¿ç”¨ä¸‰ä¸ªæ¨¡å‹è¯„ä¼°æ ‡æ³¨è´¨é‡
"""

import asyncio
import json
import os
import tempfile
import uuid
import csv
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import shutil
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, File, HTTPException, UploadFile, BackgroundTasks, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel

# å¯¼å…¥ç°æœ‰çš„æ¨¡å—
from benchmarks.InteractComp import InteractCompBenchmark
from workflow.InteractComp import InteractCompAgent
from utils.logs import logger
from utils.user_manager import UserManager, UserDataManager

app = FastAPI(title="InteractCompå¤šç”¨æˆ·æ ‡æ³¨è´¨é‡æµ‹è¯•API", version="3.0.0")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True, 
    allow_methods=["*"],
    allow_headers=["*"],
)

# å›ºå®šçš„ä¸‰ä¸ªè¯„ä¼°æ¨¡å‹
EVALUATION_MODELS = [
    "gpt-5-mini",
    "gpt-5", 
    "claude-4-sonnet"
]

# åˆå§‹åŒ–ç”¨æˆ·ç®¡ç†å™¨
user_manager = UserManager()
user_data_manager = UserDataManager()

# å¹¶å‘ä»»åŠ¡ç®¡ç†å™¨
class TaskManager:
    def __init__(self):
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.executor = ThreadPoolExecutor(max_workers=15)  # æœ€å¤š5ä¸ªå¹¶å‘è¯„ä¼°ä»»åŠ¡
    
    def start_task(self, task_id: str, coro):
        """å¯åŠ¨æ–°çš„å¼‚æ­¥ä»»åŠ¡"""
        if task_id in self.running_tasks:
            logger.warning(f"ä»»åŠ¡ {task_id} å·²åœ¨è¿è¡Œä¸­")
            return
        
        # åŒ…è£…åç¨‹ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†
        async def wrapped_coro():
            try:
                await coro
                logger.info(f"ä»»åŠ¡ {task_id} æˆåŠŸå®Œæˆ")
            except Exception as e:
                logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}")
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                try:
                    user_data_manager.update_task_by_id(task_id, {
                        "status": "failed",
                        "error": str(e),
                        "completed_at": datetime.now().isoformat()
                    })
                except Exception as update_error:
                    logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥ {task_id}: {update_error}")
        
        task = asyncio.create_task(wrapped_coro())
        self.running_tasks[task_id] = task
        
        # ä»»åŠ¡å®Œæˆåè‡ªåŠ¨æ¸…ç†
        def cleanup(future):
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
                logger.debug(f"ä»»åŠ¡ {task_id} å·²æ¸…ç†ï¼Œå‰©ä½™è¿è¡Œä»»åŠ¡æ•°: {len(self.running_tasks)}")
        
        task.add_done_callback(cleanup)
        logger.info(f"ä»»åŠ¡ {task_id} å·²å¯åŠ¨ï¼Œå½“å‰è¿è¡Œä»»åŠ¡æ•°: {len(self.running_tasks)}")
    
    def is_task_running(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return task_id in self.running_tasks
    
    def get_running_task_count(self) -> int:
        """è·å–å½“å‰è¿è¡Œä»»åŠ¡æ•°é‡"""
        return len(self.running_tasks)
    
    def get_running_task_ids(self) -> List[str]:
        """è·å–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡IDåˆ—è¡¨"""
        return list(self.running_tasks.keys())

# åˆ›å»ºå…¨å±€ä»»åŠ¡ç®¡ç†å™¨
task_manager = TaskManager()

# Pydanticæ¨¡å‹
class UserRegister(BaseModel):
    username: str
    password: str
    display_name: Optional[str] = None

class UserLogin(BaseModel):
    username: str
    password: str

class TaskCreate(BaseModel):
    file_ids: List[str]

# è®¤è¯ä¾èµ–
async def get_current_user(authorization: Optional[str] = Header(None)):
    """è·å–å½“å‰ç”¨æˆ·"""
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="æœªæä¾›è®¤è¯ä¿¡æ¯")
    
    token = authorization[7:]  # ç§»é™¤ "Bearer "
    user_id = user_manager.validate_session(token)
    if not user_id:
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•")
    
    user_info = user_manager.get_user_info(user_id)
    if not user_info:
        raise HTTPException(status_code=401, detail="ç”¨æˆ·ä¸å­˜åœ¨")
    
    return user_info

# æ”¯æŒçš„æœç´¢å¼•æ“é…ç½®ï¼ˆç”¨äºGoogleæœç´¢ï¼‰
def get_search_config():
    """è·å–æœç´¢å¼•æ“é…ç½®"""
    try:
        config = get_config()
        return config.get('search', {})
    except:
        return {}

# é…ç½®è¯»å–å‡½æ•°
def load_config():
    """ä»config2.yamlåŠ è½½é…ç½®"""
    import yaml
    from pathlib import Path
    
    config_paths = [
        Path("config/config2.yaml"),
        Path("config2.yaml"),
        Path("./config/config2.yaml")
    ]
    
    for config_path in config_paths:
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            except Exception as e:
                logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                continue
    
    raise FileNotFoundError("æœªæ‰¾åˆ°config2.yamlé…ç½®æ–‡ä»¶")

# å…¨å±€é…ç½®
CONFIG = None

def get_config():
    """è·å–é…ç½®ï¼Œå¦‚æœæœªåŠ è½½åˆ™åŠ è½½"""
    global CONFIG
    if CONFIG is None:
        CONFIG = load_config()
    return CONFIG

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
    return {
        "message": "InteractCompå¤šç”¨æˆ·æ ‡æ³¨æ•°æ®è´¨é‡æµ‹è¯•API",
        "version": "3.0.0",
        "evaluation_models": EVALUATION_MODELS,
        "features": ["å¤šç”¨æˆ·æ”¯æŒ", "æ•°æ®å…±äº«", "ä¼šè¯ç®¡ç†"],
        "config_note": "API Keysé€šè¿‡config2.yamlæ–‡ä»¶é…ç½®",
        "status": "running"
    }

# ç”¨æˆ·è®¤è¯ç›¸å…³æ¥å£
@app.post("/auth/register")
async def register_user(user_data: UserRegister):
    """ç”¨æˆ·æ³¨å†Œ"""
    try:
        result = user_manager.register_user(
            username=user_data.username,
            password=user_data.password,
            display_name=user_data.display_name
        )
        return {
            "message": "æ³¨å†ŒæˆåŠŸ",
            "user": result
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/auth/login")
async def login_user(user_data: UserLogin):
    """ç”¨æˆ·ç™»å½•"""
    user_info = user_manager.authenticate_user(user_data.username, user_data.password)
    if not user_info:
        raise HTTPException(status_code=401, detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
    
    # åˆ›å»ºä¼šè¯
    session_token = user_manager.create_session(user_info["user_id"])
    
    return {
        "message": "ç™»å½•æˆåŠŸ",
        "user": user_info,
        "token": session_token
    }

@app.get("/auth/me")
async def get_current_user_info(current_user: dict = Depends(get_current_user)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user

@app.post("/auth/logout")
async def logout_user(authorization: Optional[str] = Header(None)):
    """ç”¨æˆ·ç™»å‡ºï¼ˆæ¸…ç†ä¼šè¯ï¼‰"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¼šè¯æ¸…ç†é€»è¾‘
    return {"message": "ç™»å‡ºæˆåŠŸ"}

# ç”¨æˆ·ç®¡ç†æ¥å£
@app.get("/users")
async def list_users(current_user: dict = Depends(get_current_user)):
    """è·å–æ‰€æœ‰ç”¨æˆ·åˆ—è¡¨"""
    users = user_manager.list_all_users()
    return {
        "users": users,
        "total": len(users)
    }

@app.post("/upload")
async def upload_file(file: UploadFile = File(...), current_user: dict = Depends(get_current_user)):
    """ä¸Šä¼ JSONLæ•°æ®æ–‡ä»¶"""
    if not file.filename.endswith(('.jsonl', '.json')):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒ.jsonlæˆ–.jsonæ–‡ä»¶")
    
    file_id = str(uuid.uuid4())
    temp_dir = Path("temp_uploads")
    temp_dir.mkdir(exist_ok=True)
    
    file_path = temp_dir / f"{file_id}_{file.filename}"
    
    with open(file_path, "wb") as buffer:
        content = await file.read()
        buffer.write(content)
    
    # ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°ç”¨æˆ·æ•°æ®
    file_info = {
        "file_id": file_id,
        "filename": file.filename,
        "size": len(content),
        "file_path": str(file_path),
        "status": "uploaded"
    }
    
    user_data_manager.save_user_file(current_user["user_id"], file_id, file_info)
    
    logger.info(f"ç”¨æˆ· {current_user['username']} ä¸Šä¼ æ–‡ä»¶: {file.filename}, ID: {file_id}")
    
    return {
        "file_id": file_id,
        "filename": file.filename,
        "size": len(content),
        "status": "uploaded"
    }

@app.get("/files")
async def get_user_files(current_user: dict = Depends(get_current_user)):
    """è·å–å½“å‰ç”¨æˆ·çš„æ–‡ä»¶åˆ—è¡¨"""
    files = user_data_manager.get_user_files(current_user["user_id"])
    return {
        "files": list(files.values()),
        "total": len(files)
    }

@app.delete("/files/{file_id}")
async def delete_user_file(file_id: str, current_user: dict = Depends(get_current_user)):
    """åˆ é™¤ç”¨æˆ·æ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å±äºå½“å‰ç”¨æˆ·
        user_files = user_data_manager.get_user_files(current_user["user_id"])
        if file_id not in user_files:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æƒé™")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ­£åœ¨è¢«ä»»åŠ¡ä½¿ç”¨
        user_tasks = user_data_manager.get_user_tasks(current_user["user_id"])
        for task_id, task in user_tasks.items():
            if task.get('status') == 'running' and file_id in task.get('file_ids', []):
                raise HTTPException(status_code=400, detail="æ–‡ä»¶æ­£åœ¨è¢«è¿è¡Œä¸­çš„ä»»åŠ¡ä½¿ç”¨ï¼Œæ— æ³•åˆ é™¤")
        
        file_info = user_files[file_id]
        file_path = file_info.get('file_path')
        
        # åˆ é™¤ç‰©ç†æ–‡ä»¶
        if file_path and os.path.exists(file_path):
            os.remove(file_path)
            logger.info(f"åˆ é™¤ç‰©ç†æ–‡ä»¶: {file_path}")
        
        # ä»ç”¨æˆ·æ•°æ®ä¸­åˆ é™¤æ–‡ä»¶è®°å½•
        user_data_manager.delete_user_file(current_user["user_id"], file_id)
        
        logger.info(f"ç”¨æˆ· {current_user['username']} åˆ é™¤æ–‡ä»¶: {file_id}")
        
        return {"success": True, "message": "æ–‡ä»¶åˆ é™¤æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_id}, é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.post("/start_test")
async def start_test(
    task_data: TaskCreate,
    current_user: dict = Depends(get_current_user)
):
    """å¼€å§‹ä¸‰æ¨¡å‹è¯„ä¼°æµ‹è¯•"""
    # éªŒè¯æ–‡ä»¶æƒé™ï¼ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼‰
    user_files = user_data_manager.get_user_files(current_user["user_id"])
    for file_id in task_data.file_ids:
        if file_id not in user_files:
            raise HTTPException(status_code=403, detail=f"æ–‡ä»¶ {file_id} ä¸å±äºå½“å‰ç”¨æˆ·")
    
    # éªŒè¯é…ç½®æ–‡ä»¶
    try:
        get_config()
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="é…ç½®æ–‡ä»¶config2.yamlæœªæ‰¾åˆ°")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é…ç½®æ–‡ä»¶é”™è¯¯: {str(e)}")
    
    # åˆ›å»ºä»»åŠ¡
    task_id = str(uuid.uuid4())
    task_info = {
        "task_id": task_id,
        "status": "pending",
        "progress": 0,
        "created_at": datetime.now().isoformat(),
        "file_ids": task_data.file_ids,
        "evaluation_models": EVALUATION_MODELS,
        "user_id": current_user["user_id"],
        "username": current_user["username"],
        "display_name": current_user["display_name"]
    }
    
    # ä¿å­˜ä»»åŠ¡åˆ°ç”¨æˆ·æ•°æ®
    user_data_manager.save_user_task(current_user["user_id"], task_id, task_info)
    
    # ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨å¯åŠ¨å¹¶å‘ä»»åŠ¡
    evaluation_coro = run_multi_model_evaluation(task_id, task_data.file_ids, current_user["user_id"])
    task_manager.start_task(task_id, evaluation_coro)
    
    logger.info(f"ç”¨æˆ· {current_user['username']} å¯åŠ¨ä¸‰æ¨¡å‹è¯„ä¼°ä»»åŠ¡: {task_id}ï¼Œå½“å‰è¿è¡Œä»»åŠ¡æ•°: {task_manager.get_running_task_count()}")
    
    return {"task_id": task_id, "status": "started", "models": EVALUATION_MODELS}

@app.get("/system/status")
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "running_tasks": task_manager.get_running_task_count(),
        "running_task_ids": task_manager.get_running_task_ids(),
        "max_concurrent_tasks": 5,
        "system_time": datetime.now().isoformat(),
        "available_slots": max(0, 5 - task_manager.get_running_task_count())
    }

@app.get("/test/{task_id}")
async def get_test_status(task_id: str, current_user: dict = Depends(get_current_user)):
    """è·å–æµ‹è¯•çŠ¶æ€"""
    # ä»å…±äº«æ•°æ®ä¸­è·å–ä»»åŠ¡ï¼ˆæ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥æŸ¥çœ‹ï¼‰
    task = user_data_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return task

@app.get("/tasks")
async def get_tasks(current_user: dict = Depends(get_current_user)):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    # ç”¨æˆ·è‡ªå·±çš„ä»»åŠ¡
    user_tasks = user_data_manager.get_user_tasks(current_user["user_id"])
    # æ‰€æœ‰ç”¨æˆ·çš„ä»»åŠ¡ï¼ˆå…±äº«æŸ¥çœ‹ï¼‰
    all_tasks = user_data_manager.get_all_tasks()
    
    return {
        "user_tasks": list(user_tasks.values()),
        "all_tasks": list(all_tasks.values()),
        "user_task_count": len(user_tasks),
        "total_task_count": len(all_tasks)
    }

@app.get("/test/{task_id}/download-csv")
async def download_csv_report(task_id: str, current_user: dict = Depends(get_current_user)):
    """ä¸‹è½½CSVæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
    # ä»å…±äº«æ•°æ®ä¸­è·å–ä»»åŠ¡ï¼ˆæ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥ä¸‹è½½ï¼‰
    task = user_data_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    if task["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡æœªå®Œæˆï¼Œæ— æ³•ä¸‹è½½æŠ¥å‘Š")
    
    # åˆ›å»ºè¯¦ç»†çš„CSVæŠ¥å‘Š
    import tempfile
    temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8')
    
    writer = csv.writer(temp_file)
    # CSVæ ‡é¢˜
    writer.writerow([
        'question', 'correct_answer', 
        'gpt5_mini_answer', 'gpt5_mini_correct',
        'gpt5_answer', 'gpt5_correct', 
        'claude4_answer', 'claude4_correct',
        'models_correct_count', 'quality_failed', 'cost',
        'created_by', 'created_at'
    ])
    
    # å†™å…¥æ•°æ®
    for item in task.get("detailed_results", []):
        writer.writerow([
            item.get("question", ""),
            item.get("correct_answer", ""),
            item.get("model_results", {}).get("gpt-5-mini", {}).get("answer", ""),           
            item.get("model_results", {}).get("gpt-5-mini", {}).get("correct", False),       
            item.get("model_results", {}).get("gpt-5", {}).get("answer", ""),               
            item.get("model_results", {}).get("gpt-5", {}).get("correct", False),           
            item.get("model_results", {}).get("claude-4-sonnet", {}).get("answer", ""),     
            item.get("model_results", {}).get("claude-4-sonnet", {}).get("correct", False), 
            item.get("correct_models_count", 0),
            item.get("quality_failed", False),
            item.get("total_cost", 0.0),
            task.get('display_name', task.get('username', 'æœªçŸ¥ç”¨æˆ·')),
            task.get('created_at', '')
        ])
    
    temp_file.close()
    
    task_creator = task.get('display_name', task.get('username', 'æœªçŸ¥ç”¨æˆ·'))
    return FileResponse(
        path=temp_file.name,
        filename=f"ä¸‰æ¨¡å‹è¯„ä¼°æŠ¥å‘Š_{task_creator}_{task_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        media_type='text/csv'
    )

async def run_multi_model_evaluation(task_id: str, file_ids: List[str], user_id: str):
    """è¿è¡Œä¸‰æ¨¡å‹è¯„ä¼°"""
    task = user_data_manager.get_task(task_id)
    if not task:
        logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        return
    
    try:
        user_data_manager.update_task(user_id, task_id, {"status": "running", "progress": 10})
        
        # 1. è¯»å–é…ç½®æ–‡ä»¶
        config = get_config()
        user_data_manager.update_task(user_id, task_id, {"progress": 20})
        
        # 2. åˆå¹¶æ•°æ®æ–‡ä»¶
        combined_file_path = await merge_uploaded_files(file_ids, task_id, user_id)
        user_data_manager.update_task(user_id, task_id, {"progress": 30})

        # 3. åˆ›å»ºå¤šæ¨¡å‹è¯„ä¼°å™¨å’ŒAgentå·¥å‚
        log_path = f"workspace/multi_model_test_{task_id}/"
        os.makedirs(log_path, exist_ok=True)

        # ä½¿ç”¨ä¿®æ”¹åçš„InteractCompBenchmarkï¼Œæ”¯æŒå¤šæ¨¡å‹è¯„ä¼°
        benchmark = InteractCompBenchmark(
            name=f"MultiModelTest_{task_id}",
            file_path=combined_file_path,
            log_path=log_path,
            grader_config="gpt-4o",
            models=EVALUATION_MODELS  # ä¼ å…¥è¯„ä¼°æ¨¡å‹åˆ—è¡¨
        )

        # åˆ›å»ºAgentå·¥å‚
        from workflow.InteractComp import create_multi_model_agent_factory
        agent_factory = create_multi_model_agent_factory(
            max_turns=5,  # å¤šæ¨¡å‹è¯„ä¼°æ—¶å‡å°‘è½®æ•°èŠ‚çœæˆæœ¬
            search_engine_type="google",
            user_config="gpt-4o"
        )
        user_data_manager.update_task(user_id, task_id, {"progress": 40})
        
        # 4. æ‰§è¡Œå¤šæ¨¡å‹è¯„ä¼°
        logger.info(f"å¼€å§‹å¤šæ¨¡å‹è¯„ä¼°: {task_id}")

        results = await benchmark.run_multi_model_evaluation(
            agent_factory, 
            max_concurrent_tasks=20
        )
        user_data_manager.update_task(user_id, task_id, {"progress": 90})
        
        # 5. å¤„ç†ç»“æœ
        avg_quality_failed_rate = results["avg_quality_failed_rate"]
        total_questions = results["total_questions"]
        quality_failed_count = results["quality_failed_count"]  
        quality_passed_count = total_questions - quality_failed_count
        total_cost = results["total_cost"]
        detailed_results = results["detailed_results"]
        
        # 6. æ›´æ–°ä»»åŠ¡ç»“æœ
        final_update = {
            "status": "completed",
            "progress": 100,
            "total_questions": total_questions,
            "quality_passed_count": quality_passed_count,  # è´¨é‡åˆæ ¼æ•°ï¼ˆå°‘æ•°æ¨¡å‹ç­”å¯¹ï¼‰
            "quality_failed_count": quality_failed_count,  # è´¨é‡ä¸åˆæ ¼æ•°ï¼ˆå¤šæ•°æ¨¡å‹ç­”å¯¹ï¼‰
            "quality_failed_rate": avg_quality_failed_rate,  # è´¨é‡ä¸åˆæ ¼ç‡
            "total_cost": total_cost,
            "detailed_results": detailed_results,
            "failed_items": [item for item in detailed_results if item["quality_failed"]],
            "completed_at": datetime.now().isoformat(),
            "evaluation_summary": {
                "models_used": EVALUATION_MODELS,
                "evaluation_logic": "è´¨é‡ä¸åˆæ ¼ = 2ä¸ªä»¥ä¸Šæ¨¡å‹ç­”å¯¹",
                "quality_standard": "ä¼˜ç§€æ ‡æ³¨åº”è¯¥è®©å¤šæ•°AIæ¨¡å‹éš¾ä»¥æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ"
            }
        }
        
        user_data_manager.update_task(user_id, task_id, final_update)
        
        # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(combined_file_path):
            os.remove(combined_file_path)
        
        logger.info(f"ä¸‰æ¨¡å‹è¯„ä¼°å®Œæˆ: {task_id}, ä¸åˆæ ¼ç‡: {avg_quality_failed_rate:.3f}")
        
    except Exception as e:
        error_update = {
            "status": "failed",
            "error": str(e),
            "completed_at": datetime.now().isoformat()
        }
        
        user_data_manager.update_task(user_id, task_id, error_update)
            
        logger.error(f"ä¸‰æ¨¡å‹è¯„ä¼°å¤±è´¥: {task_id}, é”™è¯¯: {e}")

@app.get("/config/status")
async def get_config_status():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶çŠ¶æ€"""
    try:
        config = get_config()
        models = config.get('models', {})
        
        # æ£€æŸ¥å¿…éœ€çš„æ¨¡å‹é…ç½®
        required_models = EVALUATION_MODELS
        missing_models = []
        configured_models = []
        
        for model in required_models:
            if model not in models:
                missing_models.append(f"{model} (æœªé…ç½®)")
            elif not models[model].get('api_key'):
                missing_models.append(f"{model} (ç¼ºå°‘API Key)")
            else:
                configured_models.append(model)
        
        logger.info(f"é…ç½®æ£€æŸ¥ - å·²é…ç½®: {configured_models}, ç¼ºå¤±: {missing_models}")
        
        return {
            "config_found": True,
            "models_configured": len(configured_models),
            "configured_models": configured_models,
            "required_models": required_models,
            "missing_models": missing_models,
            "ready": len(missing_models) == 0,
            "config_path": "config/config2.yaml"
        }
        
    except FileNotFoundError:
        logger.warning("é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°")
        return {
            "config_found": False,
            "error": "æœªæ‰¾åˆ° config2.yaml é…ç½®æ–‡ä»¶",
            "ready": False,
            "suggestion": "è¯·å‚è€ƒ config2.example.yaml åˆ›å»ºé…ç½®æ–‡ä»¶"
        }
    except Exception as e:
        logger.error(f"é…ç½®æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "config_found": False,
            "error": f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}",
            "ready": False
        }

async def merge_uploaded_files(file_ids: List[str], task_id: str, user_id: str = None) -> str:
    """åˆå¹¶ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶ä¸ºå•ä¸ªJSONLæ–‡ä»¶"""
    output_dir = Path("workspace") / task_id
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"temp_combined_{task_id}.jsonl"
    
    with open(output_path, 'w', encoding='utf-8') as out_f:
        for file_id in file_ids:
            # ä»ç”¨æˆ·æ•°æ®ä¸­è·å–æ–‡ä»¶è·¯å¾„
            if user_id:
                user_files = user_data_manager.get_user_files(user_id)
                if file_id not in user_files:
                    logger.warning(f"æ–‡ä»¶ {file_id} ä¸å±äºç”¨æˆ· {user_id}")
                    continue
                file_path = user_files[file_id]['file_path']
            else:
                # å›é€€åˆ°ä¸´æ—¶å­˜å‚¨æ–‡ä»¶å¤¹æœç´¢
                temp_dir = Path("temp_uploads")
                file_path = None
                for temp_file in temp_dir.glob(f"{file_id}_*"):
                    file_path = str(temp_file)
                    break
                if not file_path:
                    logger.error(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {file_id}")
                    continue
            
            with open(file_path, 'r', encoding='utf-8') as in_f:
                if file_path.endswith('.jsonl'):
                    for line in in_f:
                        if line.strip():
                            out_f.write(line)
                else:  # .json
                    data = json.load(in_f)
                    if isinstance(data, list):
                        for item in data:
                            out_f.write(json.dumps(item, ensure_ascii=False) + '\n')
                    else:
                        out_f.write(json.dumps(data, ensure_ascii=False) + '\n')
    
    return str(output_path)

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨InteractCompä¸‰æ¨¡å‹æ ‡æ³¨è´¨é‡æµ‹è¯•å¹³å°")
    print("ğŸ¤– è¯„ä¼°æ¨¡å‹:", EVALUATION_MODELS)
    print("ğŸ“Š è¯„ä¼°é€»è¾‘: 2ä¸ªä»¥ä¸Šæ¨¡å‹ç­”å¯¹ = æ ‡æ³¨è´¨é‡ä¸åˆæ ¼")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    try:
        config = load_config()
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        models = config.get('models', {})
        
        for model in EVALUATION_MODELS:
            if model in models and models[model].get('api_key'):
                print(f"âœ… {model} é…ç½®å®Œæˆ")
            else:
                print(f"âš ï¸ {model} é…ç½®ç¼ºå¤±")
                
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°config2.yamlé…ç½®æ–‡ä»¶")
        print("ğŸ“ è¯·å‚è€ƒconfig2.example.yamlåˆ›å»ºé…ç½®æ–‡ä»¶")
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    print("ğŸŒ APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ“‹ é…ç½®çŠ¶æ€: http://localhost:8000/config/status")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)